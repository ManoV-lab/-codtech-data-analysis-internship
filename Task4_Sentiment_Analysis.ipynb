{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPJb6YiJ1jE/BIZCWT4pHND"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip -q install datasets\n","\n","import re\n","import numpy as np\n","import pandas as pd\n","\n","from datasets import load_dataset\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"],"metadata":{"id":"cZRV68XulImu","executionInfo":{"status":"ok","timestamp":1769100142637,"user_tz":-330,"elapsed":5782,"user":{"displayName":"mano v","userId":"13030243786231908717"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["dataset = load_dataset(\"imdb\")\n","\n","# Put into DataFrames and shuffle so we get both classes\n","train_df = pd.DataFrame({\n","    \"text\": dataset[\"train\"][\"text\"],\n","    \"label\": dataset[\"train\"][\"label\"]\n","}).sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","test_df = pd.DataFrame({\n","    \"text\": dataset[\"test\"][\"text\"],\n","    \"label\": dataset[\"test\"][\"label\"]\n","}).sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","# Take smaller subsets (fast)\n","train_df = train_df.head(5000)\n","test_df = test_df.head(2000)\n","\n","print(\"Train class counts:\", np.bincount(train_df[\"label\"]))\n","print(\"Test class counts:\", np.bincount(test_df[\"label\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxPkKhlWlc-0","executionInfo":{"status":"ok","timestamp":1769100149569,"user_tz":-330,"elapsed":4628,"user":{"displayName":"mano v","userId":"13030243786231908717"}},"outputId":"fdc530f7-22f7-4f5b-e518-c98958fb9b50"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Train class counts: [2515 2485]\n","Test class counts: [1040  960]\n"]}]},{"cell_type":"code","source":["def clean_text(text):\n","    text = text.lower()\n","    text = re.sub(r\"<br\\s*/?>\", \" \", text)\n","    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return text\n","\n","train_texts = train_df[\"text\"].apply(clean_text).tolist()\n","test_texts  = test_df[\"text\"].apply(clean_text).tolist()\n","\n","y_train = train_df[\"label\"].to_numpy()\n","y_test  = test_df[\"label\"].to_numpy()\n","\n","print(\"Example cleaned review:\\n\", train_texts[0][:300])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0CP8NgPLle9h","executionInfo":{"status":"ok","timestamp":1769100155986,"user_tz":-330,"elapsed":2960,"user":{"displayName":"mano v","userId":"13030243786231908717"}},"outputId":"d31f41c4-b83a-4508-94ad-17302dcec142"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Example cleaned review:\n"," dumb is as dumb does in this thoroughly uninteresting supposed black comedy essentially what starts out as chris klein trying to maintain a low profile eventually morphs into an uninspired version of the three amigos only without any laughs in order for black comedy to work it must be outrageous whi\n"]}]},{"cell_type":"code","source":["vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=20000)\n","\n","X_train = vectorizer.fit_transform(train_texts)\n","X_test  = vectorizer.transform(test_texts)\n","\n","print(\"X_train shape:\", X_train.shape)\n","print(\"X_test shape:\", X_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NRsJzExwlg75","executionInfo":{"status":"ok","timestamp":1769100195685,"user_tz":-330,"elapsed":3503,"user":{"displayName":"mano v","userId":"13030243786231908717"}},"outputId":"1d4133a9-371f-4230-c73e-dc0f7427e8a9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape: (5000, 20000)\n","X_test shape: (2000, 20000)\n"]}]},{"cell_type":"code","source":["model = LogisticRegression(max_iter=1000)\n","model.fit(X_train, y_train)\n","print(\"Model trained successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaSMrDaXlqcT","executionInfo":{"status":"ok","timestamp":1769100229346,"user_tz":-330,"elapsed":334,"user":{"displayName":"mano v","userId":"13030243786231908717"}},"outputId":"3f0d8f4d-7569-4046-af9f-2e08d0d68f67"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Model trained successfully!\n"]}]},{"cell_type":"code","source":["def predict_sentiment(text):\n","    cleaned = clean_text(text)\n","    vec = vectorizer.transform([cleaned])\n","    pred = model.predict(vec)[0]\n","    prob = model.predict_proba(vec).max()\n","    label = \"Positive\" if pred == 1 else \"Negative\"\n","    return label, prob\n","\n","examples = [\n","    \"This movie was fantastic, I really loved it!\",\n","    \"Worst movie ever. Very boring and waste of time.\",\n","    \"It was okay, not bad but not great either.\"\n","]\n","\n","for e in examples:\n","    label, prob = predict_sentiment(e)\n","    print(f\"Review: {e}\\nPrediction: {label} (confidence {prob:.2f})\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3c8u5kwsmrYN","executionInfo":{"status":"ok","timestamp":1769100674745,"user_tz":-330,"elapsed":66,"user":{"displayName":"mano v","userId":"13030243786231908717"}},"outputId":"0956aa02-de1e-469a-daf4-92879be333bc"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Review: This movie was fantastic, I really loved it!\n","Prediction: Positive (confidence 0.93)\n","\n","Review: Worst movie ever. Very boring and waste of time.\n","Prediction: Negative (confidence 1.00)\n","\n","Review: It was okay, not bad but not great either.\n","Prediction: Negative (confidence 0.69)\n","\n"]}]},{"cell_type":"code","source":["y_pred = model.predict(X_test)\n","\n","print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","print(\"\\nReport:\\n\", classification_report(y_test, y_pred, target_names=[\"Negative\", \"Positive\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PavwDCeilzaS","executionInfo":{"status":"ok","timestamp":1769100699609,"user_tz":-330,"elapsed":50,"user":{"displayName":"mano v","userId":"13030243786231908717"}},"outputId":"f5142e7d-2599-4ab1-8d5d-87b77241e165"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8515\n","\n","Confusion Matrix:\n"," [[866 174]\n"," [123 837]]\n","\n","Report:\n","               precision    recall  f1-score   support\n","\n","    Negative       0.88      0.83      0.85      1040\n","    Positive       0.83      0.87      0.85       960\n","\n","    accuracy                           0.85      2000\n","   macro avg       0.85      0.85      0.85      2000\n","weighted avg       0.85      0.85      0.85      2000\n","\n"]}]},{"cell_type":"markdown","source":["### Insights\n","\n","- The IMDb dataset contains movie reviews labeled as Negative (0) and Positive (1).\n","- Text preprocessing was performed (lowercasing, removing HTML tags, removing punctuation/numbers, and extra spaces).\n","- TF‑IDF was used to convert text into numeric features representing important words in each review.\n","- A Logistic Regression model was trained on the TF‑IDF vectors to classify reviews as positive or negative.\n","- The evaluation results (accuracy, confusion matrix, and classification report) show the model performance on unseen test data.\n","- This approach can be used for real‑world review monitoring to understand customer feedback automatically."],"metadata":{"id":"0d9qm1z6mbAc"}}]}